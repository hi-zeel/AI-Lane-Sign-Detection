{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f72134f7-9a1a-4ce2-9e82-368c576af62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a copy of tutorial 3 at the start\n",
    "# but instead of faking it by dragging the car through waypoints \n",
    "# we will be giving the car simple inputs to guide it along the route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a3b3edf-87d5-4f01-a231-0457a0e793d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all tsports \n",
    "import carla # the sim library itself \n",
    "import time # to set a delay after each photo \n",
    "import cv2 # to work with images from cameras\n",
    "import numpy as np # in this example to change image representation re-shaping \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b862271e-56ae-425d-97df-64769bc10e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the sim\n",
    "\n",
    "client = carla.Client('localhost', 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8da1d05-0e15-4b91-a747-9a9456f8f6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to spawn vehicle. Check spawn point or blueprint.\n",
      "Camera is streaming live images.\n"
     ]
    }
   ],
   "source": [
    "# Define the environment/world and get possible spawn points\n",
    "client = carla.Client('localhost', 2000)\n",
    "client.set_timeout(10.0)  # Set timeout to connect to the server\n",
    "world = client.get_world()\n",
    "spawn_points = world.get_map().get_spawn_points()\n",
    "\n",
    "# Look for a blueprint of a Mini car\n",
    "vehicle_bp = world.get_blueprint_library().filter('*mini*')\n",
    "\n",
    "# Select a spawn point and spawn the vehicle\n",
    "start_point = spawn_points[0]\n",
    "vehicle = world.try_spawn_actor(vehicle_bp[0], start_point)\n",
    "\n",
    "# Check if the vehicle was spawned successfully\n",
    "if vehicle is None:\n",
    "    print(\"Failed to spawn vehicle. Check spawn point or blueprint.\")\n",
    "else:\n",
    "    print(\"Vehicle spawned successfully!\")\n",
    "\n",
    "# Camera mount offset on the car\n",
    "CAMERA_POS_Z = 3.0\n",
    "CAMERA_POS_X = -5.0\n",
    "\n",
    "# Setting up the RGB camera\n",
    "camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "camera_bp.set_attribute('image_size_x', '640')\n",
    "camera_bp.set_attribute('image_size_y', '360')\n",
    "\n",
    "camera_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z, x=CAMERA_POS_X))\n",
    "\n",
    "# Create the camera in the simulator and attach it to the vehicle\n",
    "camera = world.spawn_actor(camera_bp, camera_init_trans, attach_to=vehicle)\n",
    "\n",
    "# Camera callback function to process images\n",
    "def camera_callback(image, data_dict):\n",
    "    array = np.frombuffer(image.raw_data, dtype=np.uint8)\n",
    "    reshaped = array.reshape((image.height, image.width, 4))  # BGRA format\n",
    "    data_dict['image'] = reshaped\n",
    "\n",
    "# Camera resolution attributes\n",
    "image_w = camera_bp.get_attribute('image_size_x').as_int()\n",
    "image_h = camera_bp.get_attribute('image_size_y').as_int()\n",
    "\n",
    "# Initialize the camera data dictionary\n",
    "camera_data = {'image': np.zeros((image_h, image_w, 4))}\n",
    "\n",
    "# Start the camera and listen for images\n",
    "camera.listen(lambda image: camera_callback(image, camera_data))\n",
    "print(\"Camera is streaming live images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a1b2ba2-cc1a-47f6-9a39-5b406d25842c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define speed constants\n",
    "PREFERRED_SPEED = 20  # Target speed in some units (e.g., km/h or m/s)\n",
    "SPEED_THRESHOLD = 2  # Speed tolerance before adjustments\n",
    "\n",
    "# Adding parameters to display text on the image\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX  # Font type for OpenCV\n",
    "# Defining positions for telemetry display on the screen\n",
    "org_speed = (30, 30)  # Current speed display position\n",
    "org_steering = (30, 50)  # Future steering angle display position\n",
    "org_telemetry = (30, 70)  # Other telemetry outputs\n",
    "\n",
    "# Text properties\n",
    "fontScale = 0.8\n",
    "color = (255, 255, 255)  # White color for text\n",
    "thickness = 2  # Line thickness for text\n",
    "\n",
    "# Function to maintain speed\n",
    "def maintain_speed(current_speed):\n",
    "    \"\"\"\n",
    "    Adjust throttle to maintain desired speed.\n",
    "\n",
    "    Args:\n",
    "        current_speed (float): The current speed of the vehicle.\n",
    "\n",
    "    Returns:\n",
    "        float: Throttle value to adjust speed.\n",
    "    \"\"\"\n",
    "    if current_speed < PREFERRED_SPEED - SPEED_THRESHOLD:\n",
    "        return 0.8  # Full gas (adjust this value as needed)\n",
    "    elif current_speed > PREFERRED_SPEED + SPEED_THRESHOLD:\n",
    "        return 0.4  # Gentle throttle to slow down\n",
    "    else:\n",
    "        return 0.6  # Maintain steady speed\n",
    "\n",
    "# Example usage of displaying telemetry on an image\n",
    "def display_telemetry(image, current_speed, steering_angle):\n",
    "    \"\"\"\n",
    "    Displays telemetry data on an image.\n",
    "\n",
    "    Args:\n",
    "        image (numpy array): The image where telemetry is displayed.\n",
    "        current_speed (float): The current speed of the vehicle.\n",
    "        steering_angle (float): The current steering angle of the vehicle.\n",
    "\n",
    "    Returns:\n",
    "        numpy array: The image with telemetry overlaid.\n",
    "    \"\"\"\n",
    "    speed_text = f\"Speed: {current_speed:.2f}\"\n",
    "    steering_text = f\"Steering: {steering_angle:.2f}\"\n",
    "    telemetry_text = \"Telemetry: OK\"  # Replace with other telemetry info if needed\n",
    "\n",
    "    # Put text on the image\n",
    "    cv2.putText(image, speed_text, org_speed, font, fontScale, color, thickness)\n",
    "    cv2.putText(image, steering_text, org_steering, font, fontScale, color, thickness)\n",
    "    cv2.putText(image, telemetry_text, org_telemetry, font, fontScale, color, thickness)\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "331efa20-9d42-4e6f-99a5-651478e57100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARLA Driving Straight Demo with Camera Sensor\n",
    "\n",
    "import carla\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "# Step 1: Connect to CARLA server and get world object\n",
    "client = carla.Client('localhost', 2000)\n",
    "client.set_timeout(10.0)\n",
    "world = client.get_world()\n",
    "\n",
    "# Step 2: Spawn a vehicle in the simulation world\n",
    "blueprint_library = world.get_blueprint_library()\n",
    "vehicle_bp = blueprint_library.filter('model3')[0]\n",
    "spawn_points = world.get_map().get_spawn_points()\n",
    "spawn_point = spawn_points[0] if spawn_points else carla.Transform()\n",
    "vehicle = world.spawn_actor(vehicle_bp, spawn_point)\n",
    "\n",
    "# Step 3: Initialize camera data storage\n",
    "camera_data = {\"image\": None}\n",
    "\n",
    "# Step 4: Define a callback function to process images from the camera sensor\n",
    "def process_image(image):\n",
    "    \"\"\"\n",
    "    Callback function to process images from the CARLA camera sensor.\n",
    "    Converts raw image data into a NumPy array compatible with OpenCV.\n",
    "    \"\"\"\n",
    "    array = np.frombuffer(image.raw_data, dtype=np.uint8)\n",
    "    array = array.reshape((image.height, image.width, 4))  # BGRA format\n",
    "    camera_data[\"image\"] = array[:, :, :3]  # Keep only BGR channels (discard alpha channel)\n",
    "\n",
    "# Step 5: Attach a camera sensor to the vehicle\n",
    "camera_bp = blueprint_library.find('sensor.camera.rgb')\n",
    "camera_bp.set_attribute('image_size_x', '800')  # Width of the image\n",
    "camera_bp.set_attribute('image_size_y', '600')  # Height of the image\n",
    "camera_bp.set_attribute('fov', '90')           # Field of view in degrees\n",
    "\n",
    "spawn_point_camera = carla.Transform(carla.Location(x=1.5, z=2.4))  # Camera position relative to vehicle\n",
    "camera = world.spawn_actor(camera_bp, spawn_point_camera, attach_to=vehicle)\n",
    "camera.listen(lambda image: process_image(image))\n",
    "\n",
    "# Step 6: Main loop for driving straight demo\n",
    "cv2.namedWindow(\"RGB Camera\", cv2.WINDOW_AUTOSIZE)\n",
    "quit_demo = False\n",
    "\n",
    "while not quit_demo:\n",
    "    world.tick()  # Advance the simulation by one tick\n",
    "\n",
    "    # Apply throttle control to make the vehicle move forward\n",
    "    vehicle.apply_control(carla.VehicleControl(throttle=0.5))  # Throttle set to 50%\n",
    "\n",
    "    # Check for user input to quit ('q' key)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        quit_demo = True\n",
    "\n",
    "    # If image data is available from the camera, process and display it\n",
    "    if camera_data[\"image\"] is not None:\n",
    "        image = camera_data[\"image\"].copy()  # Make a writable copy of the image\n",
    "\n",
    "        # Get current velocity of the vehicle (returns a vector)\n",
    "        v = vehicle.get_velocity()\n",
    "\n",
    "        # Calculate speed in km/h using vector magnitude and conversion factor (3.6)\n",
    "        speed = round(3.6 * math.sqrt(v.x**2 + v.y**2 + v.z**2), 0)\n",
    "\n",
    "        # Overlay speed information on the image using OpenCV text functions\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        org_speed = (50, 50)      # Position of text on screen (x, y)\n",
    "        fontScale = 1             # Size of text\n",
    "        color = (0, 255, 0)       # Text color (green)\n",
    "        thickness = 2             # Thickness of text\n",
    "\n",
    "        # Add speed text overlay to the image\n",
    "        image = cv2.putText(image, f'Speed: {int(speed)} kmph', org_speed, font,\n",
    "                            fontScale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "        # Display the processed image in an OpenCV window\n",
    "        cv2.imshow(\"RGB Camera\", image)\n",
    "\n",
    "# Step 7: Clean up resources after exiting the loop\n",
    "cv2.destroyAllWindows()  # Close all OpenCV windows\n",
    "camera.stop()            # Stop listening to camera data\n",
    "\n",
    "# Destroy all actors in CARLA (vehicles and sensors)\n",
    "for actor in world.get_actors().filter('vehicle.*'):  # Destroy all vehicles\n",
    "    actor.destroy()\n",
    "\n",
    "for sensor in world.get_actors().filter('sensor.*'):  # Destroy all sensors\n",
    "    sensor.destroy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2dd8e8c-8b0d-4a2d-995f-b9bf42942688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Destroy all actors (vehicles and sensors)\n",
    "for actor in world.get_actors().filter('vehicle.*'):\n",
    "    actor.destroy()\n",
    "\n",
    "for sensor in world.get_actors().filter('sensor.*'):\n",
    "    sensor.destroy()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla-sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
